# -*- coding: utf-8 -*-
"""DeepLearning_Treinar.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13nPasXwH141iL9O5fqDcbtoYr5VVhpv7

# Passo 1

*   Importando as bibliotecas do TensorFlow e Keras
*   Importando as bibliotecas do numpy e PIL
*   Verificando se está utilizando GPU para o treinamento
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
tf.config.list_physical_devices('GPU')
from tensorflow.python.client import device_lib

print(device_lib.list_local_devices()) #imprimindo os tipos de dispositivos

"""# Passo 2


*   Efetuando o download do dataset de treinamento e teste (3.81 GB)
*   Descompactando o dataset
*   Ajustando o dataset para eliminar arquivos temporários e ocultos que possam ter sido criados no processo de compactação/descompactação
*   Contando o número de imagens JPG para verificar se coincide com a quantidade de imagens do dataset (4550 imagens divididas em 3 categorias: Veado, Tatu e Porco)

"""

import pathlib

!gdown --id 1j64rDwoltrcbYiVaAEI-AZTaRjISP2tv #Efetuando o download do dataset direto do meu Google Drive
!tar -xzvf /content/datasetFlorestaV3.tgz #Descompactando o dataset
data_dir = pathlib.Path('/content/datasetFlorestaV3/treinamento') #Definindo o diretório de treinamento

#Os comandos abaixo servem para remover todos os arquivos ocultos/temporários das pastas do dataset
!rm -rf /content/datasetFlorestaV3/treinamento/porco/._*
!rm -rf /content/datasetFlorestaV3/treinamento/tatu/._*
!rm -rf /content/datasetFlorestaV3/treinamento/veado/._*
!rm -rf /content/datasetFlorestaV3/teste/porco/._*
!rm -rf /content/datasetFlorestaV3/teste/tatu/._*
!rm -rf /content/datasetFlorestaV3/teste/veado/._*

image_count = len(list(data_dir.glob('*/*.JPG'))) #Contando quantas imagens possuem o dataset de treinamento
print(image_count) #verificar se o número de imagens importadas coincide com o número de imagens do dataset de treinamento

"""# Passo de debug - 1

Visualizando uma imagem de cada uma das 3 classes do dataset de treinamento para verificar se o download do dataset ocorreu corretamente
"""

veado = list(data_dir.glob('veado/*'))
PIL.Image.open(str(veado[200])) 
#Exemplo de imagem do dataset de treinamento - VEADO

porco = list(data_dir.glob('porco/*'))
PIL.Image.open(str(porco[400])) 
#Exemplo de imagem do dataset de treinamento - PORCO

tatu = list(data_dir.glob('tatu/*'))
PIL.Image.open(str(tatu[400])) 
#Exemplo de imagem do dataset de treinamento - TATU

"""# Passo 3



*   Definindo os parâmetros para o loader (tamanho do batch e dimensões das imagens)
*   Configurando o  treinamento da rede neural para utilizar 80% das imagens do dataset de treinamento (3640 imagens)
*   Configurando a validação da rede neural para utilizar 20% das imagens do dataset de treinamento (910 imagens)
*   Imprimindo as classes que serão utilizadas para a classificaço das imagens (Porco, Tatu e Veado)

"""

#Para o treinamento serão utilizados batches de 32 imagens que serão redimensionadas para 400 por 400 pixels (altura e largura)
batch_size = 32
img_height = 224
img_width = 224

#definindo que 80% das imagens do dataset será usada para treinamento
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

#definindo que 20% das imagens do dataset será usada par validação
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

#verificando se foram criadas as classes com o nomes das pastas onde estão o dataset
class_names = train_ds.class_names
print(class_names)

"""# Passo de debug - 2



*   Imprimindo 9 imagens aleatórias do dataset de treinamento juntamento com sua classificaçao.

"""

#apenas para debug
#verificar se até o momento tudo que foi feito com o dataset está correto
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

"""# Passo de debug - 3

Imprimindo na tela o formato do tensor. Com a configuração realizada no Passo 3 devemos ter como resultado:
(32, 224, 224, 3)
(32, )

Onde (32, 224, 224, 3) representa um batch de 32 imagens de 224x224x3 (o 3 se refere aos canais RGB da imagem).

E (32, ) são os rótulos correspondentes a cada uma das 32 imagens do batch
"""

for image_batch, labels_batch in train_ds:
  print(image_batch.shape)
  print(labels_batch.shape)
  break

"""# Passo 4



*   Configurando o dataset de treinamento e validação para evitar gargalos de I/O durante o treinamento
*  .cache() manterá as imagens na memória após serem carregadas do disco durante a primeira época do treinamento. Garantindo que o conjunto de dados não se torne um gargalo durante o treinamento da rede neural. Como o conjunto de dados é muito grande para caber na memória, este método para criará um cache em disco de alto desempenho
*   .prefetch() sobrepõe o pré-processamento de dados e a execução do modelo durante o treinamento, evitando gargalos de I/O no disco durante o treinamento




"""

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

"""# Passo 5

Criando o modelo da rede neural utilizando VGG16
"""

num_classes = 3 #Veado, Porco, Tatu

model = Sequential([
  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  #Primeiro bloco convolucional
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  
  #Segundo bloco convolucional
  layers.Conv2D(128, 3, padding='same', activation='relu'),
  layers.Conv2D(128, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),

  #Terceiro bloco convolucional
  layers.Conv2D(256, 3, padding='same', activation='relu'),
  layers.Conv2D(256, 3, padding='same', activation='relu'),
  layers.Conv2D(256, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),

  #Quarto bloco convolucional
  layers.Conv2D(512, 3, padding='same', activation='relu'),
  layers.Conv2D(512, 3, padding='same', activation='relu'),
  layers.Conv2D(512, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),

  #Quinto bloco convolucional
  layers.Conv2D(512, 3, padding='same', activation='relu'),
  layers.Conv2D(512, 3, padding='same', activation='relu'),
  layers.Conv2D(512, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),

  #Camadas Densas (Fully Connected)
  layers.Flatten(),
  layers.Dense(4096, activation='relu'),
  layers.Dropout(0.5),
  layers.Dense(4096, activation='relu'),
  layers.Dense(num_classes, activation = 'softmax')
])


model.summary()

"""# Passo de debug - 4

Plotando o modelo gerado para visualizar as camadas
"""

from tensorflow.python.keras.utils.vis_utils import model_to_dot
from IPython.display import SVG
import pydot
import graphviz

SVG(model_to_dot(model, show_shapes=True, show_layer_names=True, rankdir='TB',expand_nested=False, dpi=60, subgraph=False).create(prog='dot',format='svg'))

"""# Passo 6

Usando Data Augmentation para gerar novas imagens rotacionadas no eixo horizontal a partir das imagens já existentes no dataset de treinamento
"""

data_augmentation = keras.Sequential(
  [
    layers.experimental.preprocessing.RandomFlip("horizontal", 
                                                 input_shape=(img_height, 
                                                              img_width,
                                                              3)),
    layers.experimental.preprocessing.RandomRotation(0.1),
    layers.experimental.preprocessing.RandomZoom(0.1),
  ]
)

plt.figure(figsize=(10, 10))
for images, _ in train_ds.take(1):
  for i in range(9):
    augmented_images = data_augmentation(images)
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(augmented_images[0].numpy().astype("uint8"))
    plt.axis("off")

"""# Passo 7

Compilando o modelo da rede neural configurado no Passo 6
"""

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""# Passo 8

Treinando e validando o modelo utilizando o dataset de treinmento juntamente com as imagens geradas no Passo 7 (Data Augmentation) utilizando 10 épocas de treinamento.
"""

epochs=10
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

"""# Passo opcional 

Salvando a rede e seus pesos para importar posteriormente
"""

model.save("meuModeloTreinadoVGG16.h5")

"""# Passo de debug - 5

Resultado do Treinamento
"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

"""# Passo 9

Testando com a base de teste conhecida


*   Testando apenas os Tatus para ver quantos a rede acerta
*   Testando apenas os Porcos para ver quantos a rede acerta
*   Testando apenas os Veados para ver quantos a rede acerta

"""

# Testando apenas com fotos de Tatu

import matplotlib.image as mpimg
tatus = pathlib.Path('/content/datasetFlorestaV3/teste/tatu')
images = list(tatus.glob('*.JPG'))

v = 0
p = 0
t = 0

for i in images:
    img = mpimg.imread(i)
    img = keras.preprocessing.image.load_img(
        i, target_size=(img_height, img_width)
    )
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0) # Create a batch

    predictions = model.predict(img_array)
    score = tf.nn.softmax(predictions[0])

    if class_names[np.argmax(score)] == "porco":
        p = p + 1
    elif class_names[np.argmax(score)] == "tatu":
        t = t + 1
    else:
        v = v + 1
  
print('Veado: {}'.format(v)) 
print('Porco: {}'.format(p)) 
print('Tatu: {}'.format(t)) 
total = v + p + t
acerto =(t/total)*100
print('A rede acertou {:.2}% das imagens' .format(acerto))

# Testando apenas com fotos de Porcos
porcos = pathlib.Path('/content/datasetFlorestaV3/teste/porco')
images = list(porcos.glob('*.JPG'))

v = 0
p = 0
t = 0

for i in images:
    img = mpimg.imread(i)
    img = keras.preprocessing.image.load_img(
        i, target_size=(img_height, img_width)
    )
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0) # Create a batch

    predictions = model.predict(img_array)
    score = tf.nn.softmax(predictions[0])

    if class_names[np.argmax(score)] == "porco":
        p = p + 1
    elif class_names[np.argmax(score)] == "tatu":
        t = t + 1
    else:
        c = v + 1


print('Porco: {}'.format(p)) 
print('Tatu: {}'.format(t)) 
print('Veado: {}'.format(v)) 
total = v + p + t
acerto =(p/total)*100
print('A rede acertou {:.2}% das imagens' .format(acerto))

# Testando apenas com fotos de Veados
veados = pathlib.Path('/content/datasetFlorestaV3/teste/veado')
images = list(veados.glob('*.JPG'))


v = 0
p = 0
t = 0

for i in images:
    img = mpimg.imread(i)
    img = keras.preprocessing.image.load_img(
        i, target_size=(img_height, img_width)
    )
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0) # Create a batch

    predictions = model.predict(img_array)
    score = tf.nn.softmax(predictions[0])

    if class_names[np.argmax(score)] == "porco":
        p = p + 1
    elif class_names[np.argmax(score)] == "tatu":
        t = t + 1
    else:
        v = v + 1 

print('Porco: {}'.format(p)) 
print('Tatu: {}'.format(t)) 
print('Veado: {}'.format(v)) 
total = v + p + t
acerto =(v/total)*100
print('A rede acertou {:.2}% das imagens' .format(acerto))

"""# Passo opcional - 2

Classificação com score
Vendo como cada foto do dataset de teste foi classificada com seu respectivo score.
"""

# Commented out IPython magic to ensure Python compatibility.
# Apenas fotos de tatu
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

veados = pathlib.Path('/content/datasetFlorestaV3/teste/tatu')
images = list(veados.glob('*.JPG'))
for i in images:
    img = mpimg.imread(i)
    imgplot = plt.imshow(img)
    plt.show()
    img = keras.preprocessing.image.load_img(
        i, target_size=(img_height, img_width)
    )
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0) # Create a batch

    predictions = model.predict(img_array)
    score = tf.nn.softmax(predictions[0])
    print("Esse imagem é: \033[1m{}!\033[0m Com \033[1m{:.2f}%\033[0m de certeza.".format(class_names[np.argmax(score)], 100 * np.max(score)))

# Commented out IPython magic to ensure Python compatibility.
# Apenas fotos de porco
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

veados = pathlib.Path('/content/datasetFlorestaV3/teste/porco')
images = list(veados.glob('*.JPG'))
for i in images:
    img = mpimg.imread(i)
    imgplot = plt.imshow(img)
    plt.show()
    img = keras.preprocessing.image.load_img(
        i, target_size=(img_height, img_width)
    )
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0) # Create a batch

    predictions = model.predict(img_array)
    score = tf.nn.softmax(predictions[0])
    print("Esse imagem é: \033[1m{}!\033[0m Com \033[1m{:.2f}%\033[0m de certeza.".format(class_names[np.argmax(score)], 100 * np.max(score)))

# Commented out IPython magic to ensure Python compatibility.
# Apenas fotos de Veado
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

veados = pathlib.Path('/content/datasetFlorestaV3/teste/veado')
images = list(veados.glob('*.JPG'))
for i in images:
    img = mpimg.imread(i)
    imgplot = plt.imshow(img)
    plt.show()
    img = keras.preprocessing.image.load_img(
        i, target_size=(img_height, img_width)
    )
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0) # Create a batch

    predictions = model.predict(img_array)
    score = tf.nn.softmax(predictions[0])
    print("Esse imagem é: \033[1m{}!\033[0m Com \033[1m{:.2f}%\033[0m de certeza.".format(class_names[np.argmax(score)], 100 * np.max(score)))